{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fa07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import ydf\n",
    "from keras.applications import MobileNetV2 # Supposedly good model for small 64x64 images\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorFlow-based image verification...\n",
      "Corrupt file found (TF): PetImages\\Cat\\10404.jpg\n",
      "Corrupt file found (TF): PetImages\\Cat\\4351.jpg\n",
      "Corrupt file found (TF): PetImages\\Cat\\Thumbs.db\n",
      "Corrupt file found (TF): PetImages\\Dog\\11233.jpg\n",
      "Corrupt file found (TF): PetImages\\Dog\\11912.jpg\n",
      "Corrupt file found (TF): PetImages\\Dog\\2317.jpg\n",
      "Corrupt file found (TF): PetImages\\Dog\\2494.jpg\n",
      "Corrupt file found (TF): PetImages\\Dog\\9500.jpg\n",
      "Corrupt file found (TF): PetImages\\Dog\\Thumbs.db\n",
      "\n",
      "---------------------------------\n",
      "Total corrupted or problematic images found: 9\n",
      "['PetImages\\\\Cat\\\\10404.jpg', 'PetImages\\\\Cat\\\\4351.jpg', 'PetImages\\\\Cat\\\\Thumbs.db', 'PetImages\\\\Dog\\\\11233.jpg', 'PetImages\\\\Dog\\\\11912.jpg', 'PetImages\\\\Dog\\\\2317.jpg', 'PetImages\\\\Dog\\\\2494.jpg', 'PetImages\\\\Dog\\\\9500.jpg', 'PetImages\\\\Dog\\\\Thumbs.db']\n",
      "\n",
      "Deleting corrupted files...\n",
      "Deleted: PetImages\\Cat\\10404.jpg\n",
      "Deleted: PetImages\\Cat\\4351.jpg\n",
      "Deleted: PetImages\\Cat\\Thumbs.db\n",
      "Deleted: PetImages\\Dog\\11233.jpg\n",
      "Deleted: PetImages\\Dog\\11912.jpg\n",
      "Deleted: PetImages\\Dog\\2317.jpg\n",
      "Deleted: PetImages\\Dog\\2494.jpg\n",
      "Deleted: PetImages\\Dog\\9500.jpg\n",
      "Deleted: PetImages\\Dog\\Thumbs.db\n",
      "Deletion complete.\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"PetImages\"\n",
    "subfolders = [\"Cat\", \"Dog\"]\n",
    "bad_images = []\n",
    "\n",
    "print(\"Looking for Corrupt images\")\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(image_folder, subfolder)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Directory not found: {folder_path}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # We need to use a try-except block here\n",
    "        try:\n",
    "            # Read the raw file data\n",
    "            raw_image_data = tf.io.read_file(file_path)\n",
    "            \n",
    "            # Attempt to decode it using TensorFlow's engine\n",
    "            # This is the same operation that fails during training\n",
    "            tf.io.decode_image(raw_image_data)\n",
    "            \n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            # This is the specific error we are looking for!\n",
    "            print(f\"Corrupt file found: {file_path}\")\n",
    "            bad_images.append(file_path)\n",
    "        except Exception as e:\n",
    "            # Catch any other potential errors, e.g., file not readable\n",
    "            print(f\"An unexpected error occurred for file {file_path}: {e}\")\n",
    "            bad_images.append(file_path)\n",
    "\n",
    "print(\"\\n---------------------------------\")\n",
    "print(f\"Total corrupted or problematic images found: {len(bad_images)}\")\n",
    "print(bad_images)\n",
    "\n",
    "# --- Optional: Automatically delete the bad files ---\n",
    "# Uncomment the following lines to delete the files found\n",
    "print(\"\\nDeleting corrupted files...\")\n",
    "for fpath in bad_images:\n",
    "    try:\n",
    "        os.remove(fpath)\n",
    "        print(f\"Deleted: {fpath}\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting {fpath}: {e}\")\n",
    "print(\"Deletion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debba975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24991 files belonging to 2 classes.\n",
      "Using 19993 files for training.\n",
      "Found 24991 files belonging to 2 classes.\n",
      "Using 4998 files for validation.\n",
      "Class names found: ['Cat', 'Dog']\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"PetImages/\"\n",
    "img_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "# Create a training dataset directly from the directory\n",
    "# It will automatically infer class labels from the folder names\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    image_folder,\n",
    "    validation_split=0.2,  # Use 20% of the images for validation\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create a validation dataset\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    image_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Get class names (e.g., ['Cat', 'Dog'])\n",
    "class_names = train_dataset.class_names\n",
    "print(\"Class names found:\", class_names)\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "# normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "# train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "# validation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee732db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Take one batch from the dataset\n",
    "# A batch contains a tensor of images and a tensor of their corresponding labels\n",
    "for images, labels in train_dataset.take(1):\n",
    "  # `images` is a batch of images (e.g., 32 images of shape 64x64x3)\n",
    "  # `labels` is a batch of labels (e.g., 32 integers from 0 to n_classes-1)\n",
    "  \n",
    "  # Loop through the first 9 images in the batch\n",
    "  for i in range(9):\n",
    "    # Create a subplot for each image\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Display the image\n",
    "    # Note: Keras reads images as tf.Tensor, matplotlib expects NumPy arrays.\n",
    "    # We also expect pixel values to be in the range [0, 1] for floating point images.\n",
    "    # If you haven't normalized yet use uint8 float32 for normalized\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    \n",
    "    # Get the corresponding label name from the class_names list\n",
    "    label_name = class_names[labels[i]]\n",
    "    plt.title(label_name)\n",
    "    \n",
    "    # Hide the axes\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c50052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (19993, 64, 64, 3)\n",
      "Validation set shape: (4998, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_numpy(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        images.append(batch_images.numpy())\n",
    "        labels.append(batch_labels.numpy())\n",
    "    images = np.concatenate(images)\n",
    "    labels = np.concatenate(labels)\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = dataset_to_numpy(train_dataset)\n",
    "X_val, y_val = dataset_to_numpy(validation_dataset)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ba42e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened X_train shape: (19993, 12288)\n",
      "Flattened X_val shape: (4998, 12288)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Flatten images for Random Forest\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "print(\"Flattened X_train shape:\", X_train.shape)\n",
    "print(\"Flattened X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a3180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=class_names))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac12a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mail Moolbaes\\AppData\\Local\\Temp\\ipykernel_13604\\358037125.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  feature_extractor = MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Extracting features...\n",
      "Extracting features...\n",
      "\n",
      "Shape of training features: (19993, 1280)\n",
      "Shape of validation features: (4998, 1280)\n",
      "\n",
      "Training DataFrame head:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.742656        0.0   0.040768        0.0   5.307450        0.0   \n",
      "1   0.000000        0.0   0.000000        0.0   4.261316        0.0   \n",
      "2   0.000000        0.0   0.000000        0.0   0.000000        0.0   \n",
      "3   2.108096        0.0   0.105618        0.0   0.000000        0.0   \n",
      "4   0.000000        0.0   0.000000        0.0   0.000000        0.0   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_1271  \\\n",
      "0   3.168020   0.000000   0.000000   6.000000  ...      0.000000   \n",
      "1   5.842039   0.908353   0.000000   0.595312  ...      0.000000   \n",
      "2   0.000000   0.000000   0.000000   0.000000  ...      0.487298   \n",
      "3   3.023441   0.000000   0.000000   0.000000  ...      0.000000   \n",
      "4   0.000000   0.023548   2.182736   0.000000  ...      0.317611   \n",
      "\n",
      "   feature_1272  feature_1273  feature_1274  feature_1275  feature_1276  \\\n",
      "0      0.000000      0.574620           0.0      1.965135      0.600824   \n",
      "1      5.065963      0.655116           0.0      0.398146      0.000000   \n",
      "2      0.000000      1.661446           0.0      0.000000      0.000000   \n",
      "3      0.000000      2.903450           0.0      0.000000      0.000000   \n",
      "4      1.662581      0.000000           0.0      0.790676      3.878778   \n",
      "\n",
      "   feature_1277  feature_1278  feature_1279  label  \n",
      "0      4.260049      0.968153      3.476457      1  \n",
      "1      0.000000      0.000000      0.000000      1  \n",
      "2      0.000000      0.000000      0.535113      1  \n",
      "3      1.232804      2.108872      0.000000      0  \n",
      "4      0.000000      0.000000      0.000000      1  \n",
      "\n",
      "[5 rows x 1281 columns]\n",
      "\n",
      "Training YDF Random Forest model...\n",
      "Train model on 19993 examples\n",
      "Model trained in 0:01:16.623507\n",
      "\n",
      "Evaluating model performance...\n",
      "\n",
      "Evaluation Report:\n",
      "accuracy: 0.823529\n",
      "confusion matrix:\n",
      "    label (row) \\ prediction (col)\n",
      "    +------+------+------+\n",
      "    |      |    0 |    1 |\n",
      "    +------+------+------+\n",
      "    |    0 | 2202 |  240 |\n",
      "    +------+------+------+\n",
      "    |    1 |  642 | 1914 |\n",
      "    +------+------+------+\n",
      "characteristics:\n",
      "    name: '1' vs others\n",
      "    ROC AUC: 0.913231\n",
      "    PR AUC: 0.924288\n",
      "    Num thresholds: 302\n",
      "loss: 0.398986\n",
      "num examples: 4998\n",
      "num examples (weighted): 4998\n",
      "\n",
      "\n",
      "Model Accuracy on Validation Set: 82.35%\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,        # Exclude the final classification layer\n",
    "    pooling='avg',            # Average the features into a single vector per image\n",
    "    input_shape=(*img_size, 3)\n",
    ")\n",
    "\n",
    "# --- 3. Define a Function to Extract Features from a Dataset ---\n",
    "def extract_features(dataset, extractor_model):\n",
    "    \"\"\"Iterates through a tf.data.Dataset, extracts features, and returns them as NumPy arrays.\"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"Extracting features...\")\n",
    "    # Iterate through each batch of images and labels in the dataset\n",
    "    for images, labels in dataset:\n",
    "        # Use the specific preprocessing function for MobileNetV2\n",
    "        preprocessed_images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "        \n",
    "        # Get feature vectors from the extractor model\n",
    "        features = extractor_model.predict(preprocessed_images, verbose=0)\n",
    "        \n",
    "        # Store the results from the batch\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "    # Concatenate all batches into single NumPy arrays\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "# --- 4. Process Both Datasets ---\n",
    "train_features, train_labels = extract_features(train_dataset, feature_extractor)\n",
    "val_features, val_labels = extract_features(validation_dataset, feature_extractor)\n",
    "\n",
    "print(f\"\\nShape of training features: {train_features.shape}\")\n",
    "print(f\"Shape of validation features: {val_features.shape}\")\n",
    "\n",
    "# --- 5. Convert to Pandas DataFrames for YDF ---\n",
    "# Create column names for the features\n",
    "feature_columns = [f'feature_{i}' for i in range(train_features.shape[1])]\n",
    "\n",
    "# Create the training DataFrame\n",
    "train_df = pd.DataFrame(train_features, columns=feature_columns)\n",
    "train_df['label'] = train_labels\n",
    "\n",
    "# Create the validation DataFrame (which we'll use for testing)\n",
    "test_df = pd.DataFrame(val_features, columns=feature_columns)\n",
    "test_df['label'] = val_labels\n",
    "\n",
    "print(\"\\nTraining DataFrame head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# --- 6. Train and Evaluate the YDF Random Forest Model ---\n",
    "print(\"\\nTraining YDF Random Forest model...\")\n",
    "\n",
    "# Define the model. YDF will automatically detect the classification task.\n",
    "rf_model = ydf.RandomForestLearner(label=\"label\").train(train_df)\n",
    "\n",
    "# Evaluate the model's performance on the validation data\n",
    "print(\"\\nEvaluating model performance...\")\n",
    "evaluation = rf_model.evaluate(test_df)\n",
    "\n",
    "print(\"\\nEvaluation Report:\")\n",
    "print(evaluation)\n",
    "\n",
    "accuracy = evaluation.accuracy\n",
    "print(f\"\\nModel Accuracy on Validation Set: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
